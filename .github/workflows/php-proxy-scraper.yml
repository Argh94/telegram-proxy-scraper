name: Telegram Proxy Scraper

on:
  schedule:
    - cron: '0 */3 * * *'  # Ø§Ø¬Ø±Ø§ Ù‡Ø± 3 Ø³Ø§Ø¹Øª
  push:
    branches: [ main ]
  workflow_dispatch:

permissions:
  contents: write

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Ú©Ù„ ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ø±Ùˆ Ø¨Ú¯ÛŒØ± Ø¨Ø±Ø§ÛŒ pull Ø¯Ø±Ø³Øª

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.9'

      - name: Set up PHP
        uses: shivammathur/setup-php@v2
        with:
          php-version: '8.1'
          extensions: curl

      - name: Install Chrome
        uses: browser-actions/setup-chrome@v1
        with:
          chrome-version: stable
        id: setup-chrome

      - name: Verify ChromeDriver
        run: |
          chromedriver --version
          echo "Chrome installed at: ${{ steps.setup-chrome.outputs.chrome-path }}"
          echo "ChromeDriver installed at: ${{ steps.setup-chrome.outputs.chromedriver-path }}"

      - name: Ensure output files exist
        run: |
          touch proxy.txt
          mkdir -p Files
          touch Files/extracted_proxies.json
          touch Files/offline_proxies.txt

      - name: Create or update requirements.txt
        working-directory: ./Files
        run: |
          echo -e "requests\nbeautifulsoup4\nselenium\npytz\njdatetime" > requirements.txt
          cat requirements.txt

      - name: Install Python dependencies
        working-directory: ./Files
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run PHP scraper
        working-directory: ./Files
        run: |
          php extract_proxies.php > php-scraper.log 2>&1
        continue-on-error: true

      - name: Upload PHP scraper log
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: php-scraper-log
          path: Files/php-scraper.log

      - name: Run Python scraper
        working-directory: ./Files
        run: |
          python main.py > python-scraper.log 2>&1
        continue-on-error: true

      - name: Upload Python scraper log
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: python-scraper-log
          path: Files/python-scraper.log

      - name: Commit and push changes
        run: |
          git config --global user.name 'github-actions[bot]'
          git config --global user.email '41898282+github-actions[bot]@users.noreply.github.com'
          git pull origin main --rebase || true  # Ø§Ø¯ØºØ§Ù… ØªØºÛŒÛŒØ±Ø§Øª Ø±ÛŒÙ…ÙˆØª
          git add proxy.txt README.md Files/requirements.txt Files/extracted_proxies.json Files/offline_proxies.txt || true
          git commit -m "â›“ï¸â€ğŸ’¥ Argh94 Update - PHP and Python proxies" || true
          git push || true
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        continue-on-error: true
